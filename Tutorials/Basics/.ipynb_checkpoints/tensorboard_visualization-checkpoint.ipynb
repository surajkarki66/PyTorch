{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.MNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.MNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = ('zero', 'one', 'two', 'three', 'four',\n",
    "        'five', 'six', 'seven', 'eight', 'nine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # output shape = (16 * 4 * 4)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/mnist_experiment_1') # writer works is to write anything in tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_mnist_images', img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0901 15:10:03.772047 140420823340800 plugin_event_accumulator.py:321] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0901 15:10:03.772345 140420823340800 plugin_event_accumulator.py:359] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "TensorBoard 2.2.2 at http://surajkarki-Inspiron-5567:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a “Projector” to TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing trained models with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
